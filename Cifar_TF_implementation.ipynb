{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "a11.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python [default]",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "HU1hLQGyd2bw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c33b9932-65c9-47e2-e80c-5b758e83b5fa"
      },
      "cell_type": "code",
      "source": [
        "import urllib.request\n",
        "urllib.request.urlretrieve (\"https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\", \"a.tar.gz\")\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('a.tar.gz', <http.client.HTTPMessage at 0x7f581a240518>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "metadata": {
        "id": "2kKe9IO2d7EE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tarfile\n",
        "tar = tarfile.open(\"a.tar.gz\")\n",
        "tar.extractall()\n",
        "tar.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "29p8lwPZy_bn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "a6b48dc2-cc02-44ab-c466-301ee77dd850"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "\n",
        "\n",
        "def unpickle(file):\n",
        " '''Load byte data from file'''\n",
        " with open(file, 'rb') as f:\n",
        "  data = pickle.load(f, encoding='latin-1')\n",
        "  return data\n",
        "\n",
        "\n",
        "def load_cifar10_data(data_dir):\n",
        " '''Return train_data, train_labels, test_data, test_labels\n",
        " The shape of data is 32 x 32 x3'''\n",
        " train_data = None\n",
        " train_labels = []\n",
        "\n",
        " for i in range(1, 6):\n",
        "  data_dic = unpickle(data_dir + \"/data_batch_{}\".format(i))\n",
        "  if i == 1:\n",
        "   train_data = data_dic['data']\n",
        "  else:\n",
        "   train_data = np.vstack((train_data, data_dic['data']))\n",
        "  train_labels += data_dic['labels']\n",
        "\n",
        " test_data_dic = unpickle(data_dir + \"/test_batch\")\n",
        " test_data = test_data_dic['data']\n",
        " test_labels = test_data_dic['labels']\n",
        "\n",
        " train_data = train_data.reshape((len(train_data), 3, 32, 32))\n",
        " train_data = np.rollaxis(train_data, 1, 4)\n",
        " train_labels = np.array(train_labels)\n",
        "\n",
        " test_data = test_data.reshape((len(test_data), 3, 32, 32))\n",
        " test_data = np.rollaxis(test_data, 1, 4)\n",
        " test_labels = np.array(test_labels)\n",
        "\n",
        " return train_data, train_labels, test_data, test_labels\n",
        "\n",
        "data_dir = 'cifar-10-batches-py'\n",
        "\n",
        "train_data, train_labels, test_data, test_labels = load_cifar10_data(data_dir)\n",
        "\n",
        "print(train_data.shape)\n",
        "print(train_labels.shape)\n",
        "\n",
        "print(test_data.shape)\n",
        "print(test_labels.shape)\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50000, 32, 32, 3)\n",
            "(50000,)\n",
            "(10000, 32, 32, 3)\n",
            "(10000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "egoHepuBduWR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#importing required libraries\n",
        "\n",
        "#image precessing\n",
        "import cv2\n",
        "#file handling\n",
        "import os\n",
        "#obvious\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "#library to know the progress of or loops\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0Um5en6M_xh4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "46765fed-52fd-4d7c-ae04-60aab7a0240f"
      },
      "cell_type": "code",
      "source": [
        "name,count = np.unique(test_labels,return_counts=True)\n",
        "print(count)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1000 1000 1000 1000 1000 1000 1000 1000 1000 1000]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "HBUeGQT836Q5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_train = train_data\n",
        "x_test = test_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QJ3E-P894RS6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bf056755-0807-4d60-bfb3-173a6c5353b5"
      },
      "cell_type": "code",
      "source": [
        "train_labels\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([6, 9, 9, ..., 9, 1, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "id": "xwkQp4bcFjH2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#creating y\n",
        "def func(a):\n",
        "  y = []\n",
        "  for name in a:\n",
        "    if name == 0:\n",
        "      y.append((1,0,0,0,0,0,0,0,0,0))\n",
        "    elif name == 1:\n",
        "      y.append((0,1,0,0,0,0,0,0,0,0))\n",
        "    elif name == 2:\n",
        "      y.append((0,0,1,0,0,0,0,0,0,0))\n",
        "    elif name == 3:\n",
        "      y.append((0,0,0,1,0,0,0,0,0,0))\n",
        "    elif name == 4:\n",
        "      y.append((0,0,0,0,1,0,0,0,0,0))\n",
        "    elif name == 5:\n",
        "      y.append((0,0,0,0,0,1,0,0,0,0))\n",
        "    elif name == 6:\n",
        "      y.append((0,0,0,0,0,0,1,0,0,0))\n",
        "    elif name == 7:\n",
        "      y.append((0,0,0,0,0,0,0,1,0,0))\n",
        "    elif name == 8:\n",
        "      y.append((0,0,0,0,0,0,0,0,1,0))\n",
        "    elif name == 9:\n",
        "      y.append((0,0,0,0,0,0,0,0,0,1))\n",
        "  return np.array(y)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hStf9bwA6A5B",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_train = func(train_labels)\n",
        "y_test = func(test_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bKKyapg5EWfH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e01ce38f-ae58-4ed6-80d0-79fea6a00d06"
      },
      "cell_type": "code",
      "source": [
        "w = y_train\n",
        "type(w)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "metadata": {
        "id": "2H7_SFc343Lu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_train = np.reshape(x_train,(50000,3072))\n",
        "x_test = np.reshape(x_test,(10000,3072))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OQ73C-R_d-Zb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_train = x_train / 255\n",
        "x_test = x_test / 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bxyBBzYUb8g3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uUXZsl62P2h4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "input_width = 32\n",
        "input_height = 32\n",
        "input_channels = 3\n",
        "input_pixels = 3072\n",
        "\n",
        "n_conv1 = 32\n",
        "n_conv2 = 64\n",
        "stride_conv1 = 1\n",
        "stride_conv2 = 1\n",
        "conv1_k = 5\n",
        "conv2_k = 5\n",
        "max_pool1_k = 2\n",
        "max_pool2_k = 2\n",
        "\n",
        "n_hidden = 1024\n",
        "n_out = 10\n",
        "\n",
        "input_size_to_hidden = (input_width//(max_pool1_k*max_pool2_k)) * (input_height//(max_pool1_k*max_pool2_k)) *n_conv2\n",
        "n_batch = 100\n",
        "buffer_size = 1024"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "v7JUKFQSFPEf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "b3e764a2-d666-4206-d4c3-bb5f51c9b709"
      },
      "cell_type": "code",
      "source": [
        "# create input pipeline using tf.data\n",
        "dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
        "dataset = dataset.shuffle(buffer_size=buffer_size)\n",
        "dataset = dataset.apply(tf.contrib.data.batch_and_drop_remainder(batch_size=n_batch))\n",
        "iterator = dataset.make_initializable_iterator()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-15-2fa0b43c8608>:3: batch_and_drop_remainder (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.batch(..., drop_remainder=True)`.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "SWyMWNGGFUK4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# create batch iterators\n",
        "input_mini_batch, label_mini_batch = iterator.get_next()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_Ecnm3i0FWWx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
        "test_dataset = test_dataset.shuffle(buffer_size=buffer_size)\n",
        "dataset = dataset.apply(tf.contrib.data.batch_and_drop_remainder(batch_size=n_batch))\n",
        "test_iterator = test_dataset.make_initializable_iterator()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ObCgZgSkFYKw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# create batch iterators\n",
        "X_test_mini_batch, y_test_mini_batch = test_iterator.get_next()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "19p7a1u_P3Cw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "weights = {\n",
        "    \"wc1\" : tf.Variable(tf.random_normal([conv1_k, conv1_k, input_channels, n_conv1])),\n",
        "    \"wc2\" : tf.Variable(tf.random_normal([conv2_k, conv2_k, n_conv1, n_conv2])),\n",
        "    \"wh1\" : tf.Variable(tf.random_normal([input_size_to_hidden, n_hidden])),\n",
        "    \"wo\" : tf.Variable(tf.random_normal([n_hidden, n_out]))\n",
        "}\n",
        "\n",
        "biases = {\n",
        "    \"bc1\" : tf.Variable(tf.random_normal([n_conv1])),\n",
        "    \"bc2\" : tf.Variable(tf.random_normal([n_conv2])),\n",
        "    \"bh1\" : tf.Variable(tf.random_normal([n_hidden])),\n",
        "    \"bo\" : tf.Variable(tf.random_normal([n_out])),\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XJrJx9CSMDvW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def conv(x, weights, bias, strides = 1):\n",
        "    out = tf.nn.conv2d(x, weights, padding=\"SAME\", strides = [1, strides, strides, 1])\n",
        "    out = tf.nn.bias_add(out, bias)\n",
        "    out = tf.nn.relu(out)\n",
        "    return out\n",
        "\n",
        "def maxpooling(x, k = 2):\n",
        "    return tf.nn.max_pool(x, padding = \"SAME\", ksize = [1, k, k, 1], strides = [1, k, k, 1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EXPMDC9uP3Ma",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def cnn(x, weights, biases, keep_prob):\n",
        "    x = tf.reshape(x, shape = [-1 ,input_height, input_width, input_channels])\n",
        "    conv1 = conv(x, weights['wc1'], biases['bc1'], stride_conv1)\n",
        "    conv1_pool = maxpooling(conv1, max_pool1_k)\n",
        "    \n",
        "    conv2 = conv(conv1_pool, weights['wc2'], biases['bc2'], stride_conv2)\n",
        "    conv2_pool = maxpooling(conv2, max_pool2_k)\n",
        "    \n",
        "    hidden_input = tf.reshape(conv2_pool, shape = [-1, input_size_to_hidden])\n",
        "    hidden_output_before_activation = tf.add(tf.matmul(hidden_input, weights['wh1']), biases['bh1'])\n",
        "    hidden_output_before_dropout = tf.nn.relu(hidden_output_before_activation)\n",
        "    hidden_output = tf.nn.dropout(hidden_output_before_dropout, keep_prob) \n",
        "   \n",
        "    output = tf.add(tf.matmul(hidden_output, weights['wo']), biases['bo'])\n",
        "    return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TjUKufFZP3SF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x = tf.placeholder(\"float\", [None, input_pixels])\n",
        "y = tf.placeholder(tf.int32, [None, n_out])\n",
        "keep_prob = tf.placeholder(\"float\")\n",
        "pred = cnn(x, weights, biases, keep_prob)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fnJBbJTyP6Te",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=pred, labels = y))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JhVX2OeHQOkg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "optimizer = tf.train.AdamOptimizer()\n",
        "optimize = optimizer.minimize(cost)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rPjJ1N4QQd-e",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sess = tf.Session()\n",
        "sess.run(tf.global_variables_initializer())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "w1c9MWknLju_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vLAI8Wg9Cr7J",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def func2(x1,y1):\n",
        "  predictions = tf.argmax(pred, 1)\n",
        "  correct_labels = tf.argmax(y, 1)\n",
        "  correct_predictions = tf.equal(predictions, correct_labels)\n",
        "  predictions,correct_preds  = sess.run([predictions, correct_predictions], feed_dict={x:x1,\n",
        "                                              y:y1, keep_prob:1.0})\n",
        "  return correct_preds.sum()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BI21xKALd-ag",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1697
        },
        "outputId": "aab1e7e2-ed0a-4dbf-cfa8-5e3f256033ca"
      },
      "cell_type": "code",
      "source": [
        "n_epochs = 50\n",
        "for epoch in range(0,n_epochs):\n",
        "    epoch_loss = 0\n",
        "    sess.run(iterator.initializer)\n",
        "    \n",
        "    while True:\n",
        "        try:\n",
        "            X_for_train, y_for_train = sess.run([input_mini_batch, label_mini_batch])\n",
        "            t, c = sess.run([optimize, cost], feed_dict={x: X_for_train, y: y_for_train, keep_prob: 1.0})\n",
        "            epoch_loss += c\n",
        "        except tf.errors.OutOfRangeError:\n",
        "            break\n",
        "\n",
        "    # print loss\n",
        "    print(f\"Epoch {epoch} out of {n_epochs}, loss: {epoch_loss}\")\n",
        "    \n",
        "    # print train and test accuracies\n",
        "    # calculate_accuracy()\n",
        "    print(\"Accuracy: \", func2(x_test, y_test))\n"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0 out of 50, loss: 138142.53160095215\n",
            "Accuracy:  3904\n",
            "Epoch 1 out of 50, loss: 111694.20513916016\n",
            "Accuracy:  3842\n",
            "Epoch 2 out of 50, loss: 90728.72596740723\n",
            "Accuracy:  3900\n",
            "Epoch 3 out of 50, loss: 74203.3357925415\n",
            "Accuracy:  3915\n",
            "Epoch 4 out of 50, loss: 60784.30824661255\n",
            "Accuracy:  4023\n",
            "Epoch 5 out of 50, loss: 50354.1953125\n",
            "Accuracy:  4034\n",
            "Epoch 6 out of 50, loss: 41507.71926116943\n",
            "Accuracy:  3990\n",
            "Epoch 7 out of 50, loss: 34064.859535217285\n",
            "Accuracy:  4121\n",
            "Epoch 8 out of 50, loss: 28092.03595352173\n",
            "Accuracy:  4157\n",
            "Epoch 9 out of 50, loss: 23219.942516326904\n",
            "Accuracy:  4067\n",
            "Epoch 10 out of 50, loss: 19132.151475906372\n",
            "Accuracy:  4127\n",
            "Epoch 11 out of 50, loss: 15955.313710212708\n",
            "Accuracy:  4147\n",
            "Epoch 12 out of 50, loss: 13075.859302520752\n",
            "Accuracy:  4171\n",
            "Epoch 13 out of 50, loss: 10714.423099040985\n",
            "Accuracy:  4218\n",
            "Epoch 14 out of 50, loss: 9259.935616016388\n",
            "Accuracy:  4180\n",
            "Epoch 15 out of 50, loss: 7473.301973581314\n",
            "Accuracy:  4118\n",
            "Epoch 16 out of 50, loss: 6520.881479978561\n",
            "Accuracy:  4180\n",
            "Epoch 17 out of 50, loss: 5355.497644662857\n",
            "Accuracy:  4213\n",
            "Epoch 18 out of 50, loss: 4508.838780999184\n",
            "Accuracy:  4138\n",
            "Epoch 19 out of 50, loss: 3741.4446674585342\n",
            "Accuracy:  4268\n",
            "Epoch 20 out of 50, loss: 3413.9869334101677\n",
            "Accuracy:  4238\n",
            "Epoch 21 out of 50, loss: 3196.5350579619408\n",
            "Accuracy:  4284\n",
            "Epoch 22 out of 50, loss: 2607.4024732112885\n",
            "Accuracy:  4275\n",
            "Epoch 23 out of 50, loss: 2355.701645255089\n",
            "Accuracy:  4295\n",
            "Epoch 24 out of 50, loss: 1974.519647449255\n",
            "Accuracy:  4323\n",
            "Epoch 25 out of 50, loss: 1661.2762497961521\n",
            "Accuracy:  4363\n",
            "Epoch 26 out of 50, loss: 1522.6695844382048\n",
            "Accuracy:  4349\n",
            "Epoch 27 out of 50, loss: 1644.7993249297142\n",
            "Accuracy:  4337\n",
            "Epoch 28 out of 50, loss: 1562.7726233005524\n",
            "Accuracy:  4275\n",
            "Epoch 29 out of 50, loss: 1410.5711313560605\n",
            "Accuracy:  4384\n",
            "Epoch 30 out of 50, loss: 1121.510961115615\n",
            "Accuracy:  4374\n",
            "Epoch 31 out of 50, loss: 1064.2956851422787\n",
            "Accuracy:  4447\n",
            "Epoch 32 out of 50, loss: 1124.4503944675962\n",
            "Accuracy:  4409\n",
            "Epoch 33 out of 50, loss: 1027.8274320014752\n",
            "Accuracy:  4394\n",
            "Epoch 34 out of 50, loss: 810.7926773576182\n",
            "Accuracy:  4387\n",
            "Epoch 35 out of 50, loss: 951.885676091897\n",
            "Accuracy:  4451\n",
            "Epoch 36 out of 50, loss: 909.0987655062345\n",
            "Accuracy:  4423\n",
            "Epoch 37 out of 50, loss: 833.69807079525\n",
            "Accuracy:  4449\n",
            "Epoch 38 out of 50, loss: 716.2703084994782\n",
            "Accuracy:  4353\n",
            "Epoch 39 out of 50, loss: 662.5890034425829\n",
            "Accuracy:  4393\n",
            "Epoch 40 out of 50, loss: 695.4068129067284\n",
            "Accuracy:  4432\n",
            "Epoch 41 out of 50, loss: 516.2513614927685\n",
            "Accuracy:  4450\n",
            "Epoch 42 out of 50, loss: 588.1360675488146\n",
            "Accuracy:  4457\n",
            "Epoch 43 out of 50, loss: 697.757836923608\n",
            "Accuracy:  4527\n",
            "Epoch 44 out of 50, loss: 644.1395245285157\n",
            "Accuracy:  4506\n",
            "Epoch 45 out of 50, loss: 507.6293708194323\n",
            "Accuracy:  4483\n",
            "Epoch 46 out of 50, loss: 573.428855919735\n",
            "Accuracy:  4535\n",
            "Epoch 47 out of 50, loss: 601.873930810295\n",
            "Accuracy:  4610\n",
            "Epoch 48 out of 50, loss: 465.89497590992966\n",
            "Accuracy:  4608\n",
            "Epoch 49 out of 50, loss: 445.2323576822671\n",
            "Accuracy:  4507\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "WvW9FyUYSJqi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#print(func2(x_train,y_train))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}